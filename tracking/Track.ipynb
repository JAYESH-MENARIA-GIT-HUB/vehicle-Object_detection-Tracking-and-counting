{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TGEAeHyFkX_e","executionInfo":{"status":"ok","timestamp":1648693569164,"user_tz":-330,"elapsed":29551,"user":{"displayName":"jayesh Menaria","userId":"16566300595735937464"}},"outputId":"fc9b0e34-9038-4640-9b72-d9965cc5bb60"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"TGEAeHyFkX_e"},{"cell_type":"code","source":["cd /content/drive/MyDrive/Pytorch_and_cv/Assingment/Artenal/TRAIN/workspace/training_demo/Yolo-v4-DeepSort"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IG6Cx6wcy6Al","executionInfo":{"status":"ok","timestamp":1648693628300,"user_tz":-330,"elapsed":12,"user":{"displayName":"jayesh Menaria","userId":"16566300595735937464"}},"outputId":"1a957e2f-7559-441a-9473-896d590053dc"},"id":"IG6Cx6wcy6Al","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Pytorch_and_cv/Assingment/Artenal/TRAIN/workspace/training_demo/Yolo-v4-DeepSort\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"id":"601b741a","executionInfo":{"status":"ok","timestamp":1648693695835,"user_tz":-330,"elapsed":377,"user":{"displayName":"jayesh Menaria","userId":"16566300595735937464"}}},"outputs":[],"source":["import os\n","# comment out below line to enable tensorflow logging outputs\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","import time\n","import tensorflow as tf\n","\n","import core.utils as utils\n","\n","from tensorflow.python.saved_model import tag_constants\n","\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from tensorflow.compat.v1 import ConfigProto\n","from tensorflow.compat.v1 import InteractiveSession\n","# deep sort imports\n","from deep_sort import preprocessing, nn_matching\n","from deep_sort.detection import Detection\n","from deep_sort.tracker import Tracker\n","from tools import generate_detections as gdet"],"id":"601b741a"},{"cell_type":"code","execution_count":6,"metadata":{"id":"87973d51","scrolled":true,"executionInfo":{"status":"ok","timestamp":1648693709886,"user_tz":-330,"elapsed":533,"user":{"displayName":"jayesh Menaria","userId":"16566300595735937464"}}},"outputs":[],"source":["def get_prediction(pred_bbox,threshold=.45):\n","    boxs,scors,classe = [],[],[]\n","    boxes = np.array(pred_bbox[\"detection_boxes\"][0])\n","    classes = np.array(pred_bbox[\"detection_classes\"][0])\n","    scores = np.array(pred_bbox[\"detection_scores\"][0])\n","    \n","    for box,scor,cls in zip(boxes,scores,classes):\n","        if scor > threshold-.20:\n","            boxs.append(box),scors.append(scor),classe.append(cls)\n","#     if len(classe)<num_detection:\n","#         for appnd_extra in range(len(classe),num_detection):\n","#             boxs.append([0,0,0,0]),scors.append(0),classe.append(1)\n","    return tf.constant(boxs,dtype=np.float32),tf.constant(scors,dtype=np.float32),tf.constant(classe,dtype=np.float32),tf.constant(len(classe))"],"id":"87973d51"},{"cell_type":"code","execution_count":29,"metadata":{"id":"ccfe1c07","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648695845482,"user_tz":-330,"elapsed":14043,"user":{"displayName":"jayesh Menaria","userId":"16566300595735937464"}},"outputId":"cd364f8b-1af8-4e13-ecad-11afb774f669"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"]}],"source":["max_cosine_distance = 0.4\n","nn_budget = None\n","nms_max_overlap = 1.0\n","\n","# initialize deep sort\n","model_filename = 'deep_sort_model/mars-small128.pb'\n","encoder = gdet.create_box_encoder(model_filename, batch_size=1)\n","# calculate cosine distance metric\n","metric = nn_matching.NearestNeighborDistanceMetric(\"cosine\", max_cosine_distance, nn_budget)\n","# initialize tracker\n","tracker = Tracker(metric)\n","\n","# load configuration for object detector\n","config = ConfigProto()\n","config.gpu_options.allow_growth = True\n","session = InteractiveSession(config=config)\n","STRIDES, ANCHORS, NUM_CLASS, XYSCALE = utils.load_config()\n","\n","saved_model_loaded = tf.saved_model.load('/content/drive/MyDrive/Pytorch_and_cv/Assingment/Artenal/TRAIN/workspace/training_demo/exported-models/ssd_mobilenet/saved_model/', tags=[tag_constants.SERVING])\n","infer = saved_model_loaded.signatures['serving_default']"],"id":"ccfe1c07"},{"cell_type":"code","source":["from google.colab.patches import cv2_imshow"],"metadata":{"id":"2hXmEgnh05z8","executionInfo":{"status":"ok","timestamp":1648694202045,"user_tz":-330,"elapsed":7,"user":{"displayName":"jayesh Menaria","userId":"16566300595735937464"}}},"id":"2hXmEgnh05z8","execution_count":19,"outputs":[]},{"cell_type":"code","execution_count":21,"metadata":{"id":"855fbe1e","executionInfo":{"status":"ok","timestamp":1648694248185,"user_tz":-330,"elapsed":4,"user":{"displayName":"jayesh Menaria","userId":"16566300595735937464"}}},"outputs":[],"source":["colors = {'aut':[227,172,7], 'bus':[17,17,195], 'car':[0,103,82], 'lcv':[170,84,8], 'mot':[46,46,46], 'mul':[192,3,3], 'tra':[18,255,24], 'tru':[52,2,182]}"],"id":"855fbe1e"},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":433},"id":"daa58544","outputId":"64e30487-c981-49b8-e80c-fe492cceb08c","executionInfo":{"status":"error","timestamp":1648697106613,"user_tz":-330,"elapsed":15785,"user":{"displayName":"jayesh Menaria","userId":"16566300595735937464"}}},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1610\u001b[0m           return self._call_with_structured_signature(args, kwargs,\n\u001b[0;32m-> 1611\u001b[0;31m                                                       cancellation_manager)\n\u001b[0m\u001b[1;32m   1612\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstructured_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_with_structured_signature\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonicalize_function_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structured_signature_check_missing_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structured_signature_check_unexpected_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_structured_signature_check_missing_args\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1706\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmissing_arguments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1707\u001b[0;31m       raise TypeError(f\"{self._structured_signature_summary()} missing \"\n\u001b[0m\u001b[1;32m   1708\u001b[0m                       \u001b[0;34m\"required arguments: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: signature_wrapper(*, input_tensor) missing required arguments: input_tensor.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-019d0ca8ec64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mpred_bbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1599\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mdo\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     \"\"\"\n\u001b[0;32m-> 1601\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1613\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1614\u001b[0m             return self._call_with_flat_signature(args, kwargs,\n\u001b[0;32m-> 1615\u001b[0;31m                                                   cancellation_manager)\n\u001b[0m\u001b[1;32m   1616\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1617\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mstructured_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_with_flat_signature\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1666\u001b[0m                         \u001b[0;34mf\"#{i}(zero-based) to be a Tensor; \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m                         f\"got {type(arg).__name__} ({arg}).\")\n\u001b[0;32m-> 1668\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1670\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_with_structured_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m    132\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_unused_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     return super(_WrapperFunction, self)._call_flat(args, captured_inputs,\n\u001b[0;32m--> 134\u001b[0;31m                                                     cancellation_manager)\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["video_path = \"/content/drive/MyDrive/Pytorch_and_cv/Assingment/Artenal/TRAIN/workspace/training_demo/Tests/INDTraffic.mp4\" # webcam\n","# begin video capture\n","cap = cv2.VideoCapture(video_path)\n","\n","out = None\n","save = True\n","\n","\n","save_video_path = \"/content/drive/MyDrive/Pytorch_and_cv/Assingment/Artenal/TRAIN/workspace/training_demo/Tests/INDTraffic12.mp4\"\n","\n","if save:\n","    # by default VideoCapture returns float instead of int\n","    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","    fps = int(cap.get(cv2.CAP_PROP_FPS))\n","\n","    out = cv2.VideoWriter(save_video_path,cv2.VideoWriter_fourcc(*'DIVX'), 29, (width, height))\n","count_cars = []\n","\n","# while video is running\n","while True:\n","    ret, frame = cap.read()\n","\n","    if ret:\n","        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","    else:\n","        print('Video has ended!')\n","        break\n","\n","\n","    image_data = frame[np.newaxis, ...].astype(np.float32)\n","    \n","    start_time = time.time()\n","\n","    batch_data = tf.constant(image_data,dtype=np.uint8)\n","    pred_bbox = infer(batch_data)\n","\n","\n","    boxes, scores, classes, valid_detections = get_prediction(pred_bbox,threshold=.48)\n","\n","    # convert data to numpy arrays and slice out unused element\n","    bboxes = boxes.numpy()\n","    scores = scores.numpy()\n","    classes = classes.numpy()\n","    \n","    # format bounding boxes from normalized ymin, xmin, ymax, xmax ---> xmin, ymin, width, height\n","    original_h, original_w, _ = frame.shape\n","    bboxes = utils.format_boxes(bboxes, original_h, original_w)\n","\n","\n","\n","    # read in all class names from config\n","    class_names = {1: 'auto', 2: 'bus', 3: 'car', 4: 'lcv', 5: 'motorcycle', 6: 'multiaxle', 7: 'tractor', 8: 'truck'}\n","    \n","    # loop through objects and use class index to get class name, allow only classes in allowed_classes list\n","    names = []\n","    for cls in classes:\n","        class_name = class_names[cls]\n","        names.append(class_name)\n","    names = np.array(names)\n","\n","    # encode yolo detections and feed to tracker\n","    features = encoder(frame, bboxes)\n","    \n","    detections = [Detection(bbox, score, class_name, feature) for bbox, score, class_name, feature in zip(bboxes, scores, names, features)]\n","\n","\n","    # run non-maxima supression\n","    boxs = np.array([d.tlwh for d in detections])\n","    scores = np.array([d.confidence for d in detections])\n","    classes = np.array([d.class_name for d in detections])\n","    indices = preprocessing.non_max_suppression(boxs, classes, nms_max_overlap, scores)\n","    detections = [detections[i] for i in indices]       \n","    # Call the tracker\n","    tracker.predict()\n","    tracker.update(detections)\n","\n","    # update tracks\n","    for track in tracker.tracks:\n","        if not track.is_confirmed() or track.time_since_update > 1:\n","            continue \n","        bbox = track.to_tlbr()\n","        class_name = track.get_class()\n","        # draw bbox on screen\n","        color = colors[class_name[0:3]]\n","        cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), color, 2)\n","        cv2.rectangle(frame, (int(bbox[0]), int(bbox[1]-30)), (int(bbox[0])+(len(class_name)+len(str(track.track_id)))*17, int(bbox[1])), color, -1)\n","        cv2.putText(frame, class_name + \"-\" + str(track.track_id),(int(bbox[0]), int(bbox[1]-10)),0, 0.75, (255,255,255),2)\n","        \n","        count_cars.append(class_name+str(track.track_id))\n","    \n","    \n","    result = np.asarray(frame)\n","    result = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n","    \n","    # put total vehicle\n","    total_count = len(set(count_cars))\n","    cv2.putText(result,\"Total vehicle count \"+str(total_count),(10,50),cv2.FONT_HERSHEY_COMPLEX,1,(255,50,50),2)\n","\n","#     cv2.imshow(\"Output Video\", result)\n","    # if output flag is set, save video file\n","    if save:\n","        out.write(result)\n","\n","    if cv2.waitKey(1) & 0xFF == ord('q'): \n","        break\n","\n","cv2.destroyAllWindows()"],"id":"daa58544"},{"cell_type":"code","execution_count":null,"metadata":{"id":"65a05e3b"},"outputs":[],"source":["frame = cv2.imread(\"G:/My Drive/Pytorch_and_cv/Assingment/Artenal/TRAIN/workspace/training_demo/Tests/images.jpg\")\n","frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","\n","\n","image_data = frame[np.newaxis, ...].astype(np.float32)\n","\n","start_time = time.time()\n","\n","batch_data = tf.constant(image_data,dtype=np.uint8)\n","pred_bbox = infer(batch_data)\n","\n","\n","boxes = pred_bbox[\"detection_boxes\"]\n","pred_conf = pred_bbox[\"detection_scores\"]\n","        "],"id":"65a05e3b"},{"cell_type":"code","execution_count":null,"metadata":{"id":"667fe750","scrolled":true},"outputs":[],"source":["boxes, scores, classes, valid_detections = get_prediction(pred_bbox,threshold=.45,num_detection=50)"],"id":"667fe750"},{"cell_type":"code","execution_count":null,"metadata":{"id":"bacb37de"},"outputs":[],"source":["# convert data to numpy arrays and slice out unused elements\n","num_objects = valid_detections.numpy()\n","bboxes = boxes.numpy()\n","bboxes = bboxes[0:int(num_objects)]\n","scores = scores.numpy()\n","scores = scores[0:int(num_objects)]\n","classes = classes.numpy()\n","classes = classes[0:int(num_objects)]\n"],"id":"bacb37de"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3e5e209f"},"outputs":[],"source":["# format bounding boxes from normalized ymin, xmin, ymax, xmax ---> xmin, ymin, width, height\n","original_h, original_w, _ = frame.shape\n","bboxes = utils.format_boxes(bboxes, original_h, original_w)\n","\n","# store all predictions in one parameter for simplicity when calling functions\n","pred_bbox = [bboxes, scores, classes, num_objects]\n","\n","# read in all class names from config\n","class_names = class_name\n","\n","# by default allow all classes in .names file\n","# allowed_classes = list(class_names.values())\n","\n","# custom allowed classes (uncomment line below to customize tracker for only people)\n","allowed_classes = [\"auto\",'bus','car','lcv','motorcycle','multiaxle','tractor','truck']\n"],"id":"3e5e209f"},{"cell_type":"code","execution_count":null,"metadata":{"id":"d28db175"},"outputs":[],"source":["names = []\n","for cls in classes:\n","    class_name = class_names[int(cls)]\n","    names.append(class_name)\n","names = np.array(names)\n","count = len(names)"],"id":"d28db175"},{"cell_type":"code","execution_count":null,"metadata":{"id":"db818dc4"},"outputs":[],"source":["cv2.destroyAllWindows()"],"id":"db818dc4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"615e138f"},"outputs":[],"source":[""],"id":"615e138f"}],"metadata":{"accelerator":"GPU","colab":{"name":"Untitled.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":5}